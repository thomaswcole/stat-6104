{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Random Projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianRandomProjection:\n",
    "    def __init__(self, n_components, random_state=None):\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.projection_matrix = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_features = X.shape[1]\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        # Generate a random Gaussian matrix\n",
    "        self.projection_matrix = rng.normal(0, 1 / np.sqrt(self.n_components), size=(n_features, self.n_components))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.projection_matrix is None:\n",
    "            raise ValueError(\"Projection matrix not initialized. Call fit first.\")\n",
    "        return X @ self.projection_matrix\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(100, 50)\n",
    "grp = GaussianRandomProjection(n_components=20, random_state=42)\n",
    "X_projected = grp.fit_transform(X)\n",
    "print(X_projected.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sparse Random Projection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseRandomProjection:\n",
    "    def __init__(self, n_components, density='auto', random_state=None):\n",
    "        self.n_components = n_components\n",
    "        self.density = density\n",
    "        self.random_state = random_state\n",
    "        self.projection_matrix = None\n",
    "\n",
    "    def _generate_sparse_matrix(self, n_features):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "\n",
    "        if self.density == 'auto':\n",
    "            self.density = 1 / np.sqrt(n_features)  # Recommended in literature\n",
    "\n",
    "        # Define probability thresholds for sparse matrix\n",
    "        prob_zero = 1 - 2 * self.density\n",
    "        prob_pos = self.density\n",
    "        prob_neg = self.density\n",
    "\n",
    "        # Generate the random sparse projection matrix\n",
    "        rand_vals = rng.uniform(0, 1, size=(n_features, self.n_components))\n",
    "        projection_matrix = np.zeros((n_features, self.n_components))\n",
    "\n",
    "        projection_matrix[rand_vals < prob_pos] = 1\n",
    "        projection_matrix[rand_vals > (1 - prob_neg)] = -1\n",
    "\n",
    "        # Normalize by sqrt(density)\n",
    "        return projection_matrix / np.sqrt(self.density * n_features)\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_features = X.shape[1]\n",
    "        self.projection_matrix = self._generate_sparse_matrix(n_features)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.projection_matrix is None:\n",
    "            raise ValueError(\"Projection matrix not initialized. Call fit first.\")\n",
    "        return X @ self.projection_matrix\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(100, 50)  # 100 samples, 50 features\n",
    "srp = SparseRandomProjection(n_components=20, random_state=42)\n",
    "X_projected = srp.fit_transform(X)\n",
    "print(X_projected.shape)  # Should be (100, 20)\n",
    "X_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fast Johnson-Lindenstrauss Lemma**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import hadamard\n",
    "\n",
    "class FJLTProjection:\n",
    "    def __init__(self, n_components, random_state=None):\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.projection_matrix = None\n",
    "        self.diagonal_matrix = None\n",
    "        self.P = None\n",
    "\n",
    "    def _random_sign_flip(self, n):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        return np.diag(rng.choice([-1, 1], size=n))\n",
    "    \n",
    "    def _pad_to_power_of_two(self, X):\n",
    "        n_features = X.shape[1]\n",
    "        next_power = 2 ** int(np.ceil(np.log2(n_features)))\n",
    "        if next_power != n_features:\n",
    "            padding = next_power - n_features\n",
    "            return np.hstack([X, np.zeros((X.shape[0], padding))])\n",
    "        return X\n",
    "    \n",
    "    def _truncate_back(self, X_transformed, original_dim):\n",
    "        return X_transformed[:, :original_dim]\n",
    "\n",
    "    def fit(self, X):\n",
    "        n_samples, n_features = X.shape\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        # Step 1: Pad input to nearest power of two (Hadamard requires this)\n",
    "        X_padded = self._pad_to_power_of_two(X)\n",
    "        padded_dim = X_padded.shape[1]\n",
    "        \n",
    "        # Step 2: Create random sign flip matrix D\n",
    "        self.diagonal_matrix = self._random_sign_flip(padded_dim)\n",
    "        \n",
    "        # Step 3: Create random sparse matrix P (column sampling)\n",
    "        k = self.n_components\n",
    "        self.P = np.zeros((padded_dim, k))\n",
    "        selected_cols = rng.choice(padded_dim, size=k, replace=False)\n",
    "        self.P[selected_cols, np.arange(k)] = 1\n",
    "        \n",
    "        # Step 4: Precompute the projection matrix: P^T * H * D\n",
    "        H = hadamard(padded_dim) / np.sqrt(padded_dim)  # Orthonormal Hadamard\n",
    "        self.projection_matrix = (self.P.T @ H @ self.diagonal_matrix).T\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.projection_matrix is None:\n",
    "            raise ValueError(\"Projection matrix not initialized. Call fit first.\")\n",
    "        \n",
    "        # Pad input to match projection matrix dimensions\n",
    "        X_padded = self._pad_to_power_of_two(X)\n",
    "        transformed = X_padded @ self.projection_matrix\n",
    "        \n",
    "        # Truncate back if needed (though typically n_components << original dim)\n",
    "        return transformed\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n"
     ]
    }
   ],
   "source": [
    "# Generate random data\n",
    "X = np.random.randn(1000, 784)  # e.g., 1000 samples of 784-dim data\n",
    "\n",
    "# Apply FJLT\n",
    "fjlt = FJLTProjection(n_components=100, random_state=42)\n",
    "X_projected = fjlt.fit_transform(X)\n",
    "\n",
    "print(X_projected.shape)  # (1000, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subsample Randomized Hadamard Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import hadamard\n",
    "\n",
    "class SRHTProjection:\n",
    "    def __init__(self, n_components, random_state=None):\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.projection_matrix = None\n",
    "        self.diagonal_matrix = None\n",
    "        self.subsample_indices = None\n",
    "        self.padded_dim = None\n",
    "\n",
    "    def _random_sign_flip(self, n):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        return np.diag(rng.choice([-1, 1], size=n))\n",
    "    \n",
    "    def _pad_to_power_of_two(self, X):\n",
    "        n_features = X.shape[1]\n",
    "        next_power = 2 ** int(np.ceil(np.log2(n_features)))\n",
    "        if next_power != n_features:\n",
    "            padding = next_power - n_features\n",
    "            return np.hstack([X, np.zeros((X.shape[0], padding))]), next_power\n",
    "        return X, n_features\n",
    "\n",
    "    def fit(self, X):\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        X_padded, self.padded_dim = self._pad_to_power_of_two(X)\n",
    "        \n",
    "        # Step 1: Random sign flipping (diagonal matrix D)\n",
    "        self.diagonal_matrix = self._random_sign_flip(self.padded_dim)\n",
    "        \n",
    "        # Step 2: Random subsampling of rows (we'll do this during transform)\n",
    "        self.subsample_indices = rng.choice(\n",
    "            self.padded_dim, \n",
    "            size=self.n_components, \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.diagonal_matrix is None or self.subsample_indices is None:\n",
    "            raise ValueError(\"Model not fitted. Call fit first.\")\n",
    "        \n",
    "        X_padded, _ = self._pad_to_power_of_two(X)\n",
    "        \n",
    "        # Apply D (random sign flip)\n",
    "        X_signed = X_padded @ self.diagonal_matrix\n",
    "        \n",
    "        # Apply Hadamard transform to each sample (efficient using FHT)\n",
    "        H = hadamard(self.padded_dim) / np.sqrt(self.padded_dim)\n",
    "        X_hadamard = X_signed @ H.T  # Equivalent to H @ X_signed.T then transpose back\n",
    "        \n",
    "        # Subsample rows\n",
    "        X_subsampled = X_hadamard[:, self.subsample_indices]\n",
    "        \n",
    "        return X_subsampled\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "    def fast_hadamard_transform(self, x):\n",
    "        \"\"\"Recursive implementation of Fast Hadamard Transform (FHT)\"\"\"\n",
    "        n = len(x)\n",
    "        if n == 1:\n",
    "            return x\n",
    "        half = n // 2\n",
    "        left = self.fast_hadamard_transform(x[:half])\n",
    "        right = self.fast_hadamard_transform(x[half:])\n",
    "        return np.concatenate([left + right, left - right]) / np.sqrt(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.99781745,  0.38341626, -0.6371556 , ...,  0.4014371 ,\n",
       "        -0.10208062,  0.35466871],\n",
       "       [ 1.70090275, -0.07608316, -0.45179103, ..., -0.4812189 ,\n",
       "         0.7495866 , -0.3840854 ],\n",
       "       [ 0.11998658, -0.87204892, -0.03830671, ...,  0.03580409,\n",
       "        -0.27628284, -0.85517851],\n",
       "       ...,\n",
       "       [ 1.23364522,  0.58882685, -1.12380621, ...,  0.3836288 ,\n",
       "        -0.32776447, -0.49034216],\n",
       "       [ 0.29777458, -0.17806748, -0.26375806, ...,  0.15823629,\n",
       "        -0.03718125, -0.55514711],\n",
       "       [ 1.49061235, -0.14056137, -0.0435471 , ...,  0.61098549,\n",
       "         0.32137928, -1.31358769]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate random data\n",
    "X = np.abs(np.random.randn(1000, 784))  # 1000 samples of 784-dim data\n",
    "\n",
    "# Apply SRHT\n",
    "srht = SRHTProjection(n_components=100, random_state=42)\n",
    "X_projected = srht.fit_transform(X)\n",
    "\n",
    "print(X_projected.shape)  # (1000, 100)\n",
    "X_projected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clarkson-Woodruff Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "class ClarksonWoodruffTransform:\n",
    "    def __init__(self, n_components, random_state=None):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        n_components : int\n",
    "            Target dimension after projection\n",
    "        random_state : int or None\n",
    "            Seed for reproducibility\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.random_state = random_state\n",
    "        self.projection_matrix = None\n",
    "        self.n_features = None\n",
    "\n",
    "    def _generate_sparse_matrix(self, n_rows, n_cols):\n",
    "        \"\"\"Generate a sparse CountSketch matrix\"\"\"\n",
    "        rng = np.random.RandomState(self.random_state)\n",
    "        \n",
    "        # Random column indices (one per row)\n",
    "        col_indices = rng.randint(0, n_cols, size=n_rows)\n",
    "        \n",
    "        # Random ±1 values\n",
    "        values = rng.choice([-1, 1], size=n_rows)\n",
    "        \n",
    "        # Row indices (0 to n_rows-1)\n",
    "        row_indices = np.arange(n_rows)\n",
    "        \n",
    "        return sparse.csr_matrix(\n",
    "            (values, (row_indices, col_indices)),\n",
    "            shape=(n_rows, n_cols)\n",
    "        )\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Generate the sparse projection matrix\"\"\"\n",
    "        self.n_features = X.shape[1]\n",
    "        \n",
    "        # Generate sparse CountSketch matrix\n",
    "        self.projection_matrix = self._generate_sparse_matrix(\n",
    "            self.n_components,\n",
    "            self.n_features\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply the sparse projection\"\"\"\n",
    "        if self.projection_matrix is None:\n",
    "            raise ValueError(\"Projection matrix not initialized. Call fit first.\")\n",
    "        return X @ self.projection_matrix.T\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Combined fit and transform\"\"\"\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1000, 10000)\n",
      "Projected shape: (1000, 500)\n"
     ]
    }
   ],
   "source": [
    "# Generate some high-dimensional sparse data\n",
    "X = sparse.random(1000, 10000, density=0.01, random_state=42)\n",
    "\n",
    "# Apply Clarkson-Woodruff Transform\n",
    "cwt = ClarksonWoodruffTransform(n_components=500, random_state=42)\n",
    "X_projected = cwt.fit_transform(X)\n",
    "\n",
    "print(f\"Original shape: {X.shape}\")\n",
    "print(f\"Projected shape: {X_projected.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Compression Algorithms*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fft\n",
    "\n",
    "def standard_compression(A, r, rOV, w):\n",
    "    m, n = A.shape\n",
    "    d = r + rOV  # Effective reduced dimension\n",
    "\n",
    "    # Step 1: Draw a Gaussian random matrix Omega_L\n",
    "    Omega_L = np.random.randn(n, d)\n",
    "\n",
    "    # Step 2: Compute B = (A A^T)^w A Omega_L\n",
    "    B = A @ Omega_L  # Initial multiplication: A Omega_L\n",
    "    for _ in range(w):\n",
    "        B = (A @ A.T) @ B # Power iteration: (A A^T) B\n",
    "\n",
    "    # Step 3: Compute the orthogonal basis Q using QR decomposition\n",
    "    Q, _ = np.linalg.qr(B)\n",
    "\n",
    "    return Q\n",
    "\n",
    "def srht_compression(A, r, rOV, w):\n",
    "\n",
    "    m, n = A.shape\n",
    "    d = r + rOV  # Effective reduced dimension\n",
    "\n",
    "    # Step 1: Generate subsampled randomized Hadamard matrix Omega_L\n",
    "    # Find smallest power of 2 greater than or equal to n\n",
    "    n_power = 2**int(np.ceil(np.log2(n)))\n",
    "    \n",
    "    # Generate Hadamard matrix of size n_power x n_power\n",
    "    H = hadamard(n_power)\n",
    "    \n",
    "    # Generate random diagonal matrix D with ±1 entries\n",
    "    D = np.diag(np.random.choice([-1, 1], size=n_power))\n",
    "    \n",
    "    # Compute randomized Hadamard transform\n",
    "    Omega_full = (1/np.sqrt(n_power)) * D @ H\n",
    "    \n",
    "    # If n < n_power, truncate the matrix to size n\n",
    "    if n < n_power:\n",
    "        Omega_full = Omega_full[:n, :]\n",
    "    \n",
    "    # Randomly subsample d columns\n",
    "    subsample_indices = np.random.choice(n_power, size=d, replace=False)\n",
    "    Omega_L = Omega_full[:, subsample_indices]\n",
    "\n",
    "    # Step 2: Compute B = (A A^T)^w A Omega_L\n",
    "    B = A @ Omega_L  # Initial multiplication: A Omega_L\n",
    "    for _ in range(w):\n",
    "        B = (A @ A.T) @ B  # Power iteration: (A A^T) B\n",
    "\n",
    "    # Step 3: Compute the orthogonal basis Q using QR decomposition\n",
    "    Q, _ = np.linalg.qr(B)\n",
    "\n",
    "    return Q\n",
    "\n",
    "def fjlt_compression(A, r, rOV, w):\n",
    "    m, n = A.shape\n",
    "    d = r + rOV  # Effective reduced dimension\n",
    "\n",
    "    # Find smallest power of 2 >= n\n",
    "    n_power = 2**int(np.ceil(np.log2(n)))\n",
    "\n",
    "    # P: Random diagonal matrix with ±1 entries\n",
    "    P = np.random.choice([-1, 1], size=n_power)\n",
    "    \n",
    "    # D: Sparse random projection matrix\n",
    "    q = 0.1\n",
    "    D = (1/np.sqrt(q)) * np.random.choice([0, 1, -1], size=(n_power, d), \n",
    "                                        p=[1-q, q/2, q/2])\n",
    "    \n",
    "    # H: Fast Walsh-Hadamard Transform via FFT\n",
    "    def apply_hadamard(x):\n",
    "        n_pow = len(x)\n",
    "        # Pad x to n_power if necessary\n",
    "        if len(x) < n_pow:\n",
    "            x = np.pad(x, (0, n_pow - len(x)), mode='constant')\n",
    "        return fft(x) * (1/np.sqrt(n_pow))\n",
    "    \n",
    "    # Construct Omega_L = D.T @ H @ P (applied to columns of A)\n",
    "    # Step 1: Apply P (element-wise multiplication) to each column of A\n",
    "    if n < n_power:\n",
    "        A_padded = np.pad(A, ((0, 0), (0, n_power - n)), mode='constant')\n",
    "    else:\n",
    "        A_padded = A\n",
    "    \n",
    "    PA = A_padded * P[np.newaxis, :]  # (m × n_power)\n",
    "    \n",
    "    # Step 2: Apply Hadamard transform to each row of PA\n",
    "    HPA = np.apply_along_axis(apply_hadamard, 1, PA)  # (m × n_power)\n",
    "    \n",
    "    # Step 3: Apply sparse projection D.T\n",
    "    Omega_L = HPA @ D  # (m × n_power) @ (n_power × d) = (m × d)\n",
    "    \n",
    "    # Step 2: Compute B = (A A^T)^w A Omega_L\n",
    "    B = Omega_L  # Since Omega_L is already m × d, no need for A @ Omega_L here\n",
    "    for _ in range(w):\n",
    "        B = (A @ A.T) @ B\n",
    "    \n",
    "    # Step 3: QR decomposition\n",
    "    Q, _ = np.linalg.qr(B)\n",
    "    return Q\n",
    "\n",
    "def cwt_compression(A, r, rOV, w):\n",
    "    m, n = A.shape\n",
    "    d = r + rOV  # Effective reduced dimension\n",
    "\n",
    "    # Step 1: Construct Clarkson-Woodruff Transform (CountSketch matrix)\n",
    "    # Parameters for sparsity (s controls the number of non-zero entries per column)\n",
    "    s = max(1, int(np.ceil(np.log(n) / np.log(d))))  # Adjust sparsity based on problem size\n",
    "    \n",
    "    # Hash functions for column indices and signs\n",
    "    hash_indices = np.random.randint(0, d, size=n)  # h: [n] -> [d]\n",
    "    signs = np.random.choice([-1, 1], size=n)       # σ: [n] -> {-1, 1}\n",
    "    \n",
    "    # Build sparse sketching matrix S (d × n)\n",
    "    S = np.zeros((d, n))\n",
    "    for j in range(n):\n",
    "        S[hash_indices[j], j] = signs[j]\n",
    "    \n",
    "    # Step 2: Compute sketch B = A S^T\n",
    "    B = A @ S.T  # (m × n) @ (n × d) = (m × d)\n",
    "    \n",
    "    # Step 3: Power iteration: B = (A A^T)^w B\n",
    "    for _ in range(w):\n",
    "        B = (A @ A.T) @ B\n",
    "    \n",
    "    # Step 4: QR decomposition to get orthonormal basis\n",
    "    Q, _ = np.linalg.qr(B)\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Randomized NMF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomized_nmf(A, r, r_ov=5, w=1, max_iter=500, tol=1e-6,compression = 'standard'):\n",
    "    \"\"\"\n",
    "    NMF with compression matrices L and R, random initialization for Y_k,\n",
    "    and multiplicative updates with proper dimension handling.\n",
    "    \"\"\"\n",
    "    m, n = A.shape\n",
    "    d = r + r_ov  # Effective reduced dimension\n",
    "\n",
    "    # --- Step 1: Compute compression matrices L and R ---\n",
    "    if compression == 'standard':\n",
    "        L = standard_compression(A, r, r_ov, w)      # m × d\n",
    "        R = standard_compression(A.T, r, r_ov, w).T  # d × n\n",
    "    elif compression == 'srht':\n",
    "        L = srht_compression(A, r, r_ov, w)      # m × d\n",
    "        R = srht_compression(A.T, r, r_ov, w).T  # d × n\n",
    "    elif compression == 'fjlt':\n",
    "        L = fjlt_compression(A, r, r_ov, w)      # m × d\n",
    "        R = fjlt_compression(A.T, r, r_ov, w).T  # d × n\n",
    "    elif compression == 'cwt':\n",
    "        L = cwt_compression(A, r, r_ov, w)      # m × d\n",
    "        R = cwt_compression(A.T, r, r_ov, w).T  # d × n\n",
    "    else:\n",
    "        print('Please select compression Algorithm')\n",
    "        return\n",
    "\n",
    "    # --- Step 3: Initialize Y_k as random non-negative ---\n",
    "    Y_k = np.abs(np.random.randn(r, n))  # r × n\n",
    "    Y_k = np.maximum(Y_k, 1e-6)          # Enforce non-negativity\n",
    "\n",
    "    # Initialize X\n",
    "    X_k = np.abs(np.random.randn(m, r))   # m × r\n",
    "    X_k = np.maximum(X_k, 1e-6)\n",
    "\n",
    "    # --- Main loop ---\n",
    "    errors = []\n",
    "    for k in range(max_iter):\n",
    "        # --- Update X_{k+1} ---\n",
    "        # numerator: (m × d) @ (d × r) = m × r\n",
    "        numerator = (A @ R.T) @ (R @ Y_k.T)\n",
    "        # denominator: (m × r) @ (r × d) @ (d × r) = m × r\n",
    "        denominator = X_k @ (Y_k @ R.T @ R @ Y_k.T)\n",
    "        X_k_plus1 = X_k * numerator / (denominator + 1e-10)\n",
    "        X_k_plus1 = np.maximum(X_k_plus1, 1e-6)\n",
    "\n",
    "        # --- Update Y_{k+1} ---\n",
    "        # numerator: (r × d) @ (d × n) = r × n\n",
    "        numerator = (L.T @ X_k_plus1).T @ (L.T @ A)\n",
    "        # denominator: (r × d) @ (d × r) @ (r × n) = r × n\n",
    "        denominator = (L.T @ X_k_plus1).T @ (L.T @ X_k_plus1) @ Y_k\n",
    "        Y_k_plus1 = Y_k * numerator / (denominator + 1e-10)\n",
    "        Y_k_plus1 = np.maximum(Y_k_plus1, 1e-6)\n",
    "\n",
    "        # --- Convergence check ---\n",
    "        error = np.linalg.norm(A - X_k_plus1 @ Y_k_plus1, 'fro') / np.linalg.norm(A, 'fro')\n",
    "        errors.append(error)\n",
    "\n",
    "        X_k, Y_k = X_k_plus1, Y_k_plus1\n",
    "\n",
    "    return X_k, Y_k, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
