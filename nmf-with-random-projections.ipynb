{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "import timeit\n",
    "import math\n",
    "\n",
    "from archive.randomized_projected_nmf import *\n",
    "from random_matrix import *\n",
    "from nmf import * \n",
    "from benchmark import *\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview of Algorithms**\n",
    "\n",
    "1. NNLS: Active Set Method\n",
    "    - i) Randomized Projected NMF\n",
    "        * a) Gaussian Test Matrix\n",
    "        * b) SRHT Test Matrix\n",
    "        * c) SRFT Test Matrix\n",
    "        * d) Count Sketch Matrix\n",
    "        * e) Sparse JL\n",
    "    - ii) Structured Random Projected NMF\n",
    "        * a) Gaussian Test Matrix\n",
    "        * b) SRHT Test Matrix\n",
    "        * c) SRFT Test Matrix\n",
    "        * d) Count Sketch Matrix\n",
    "        * e) Sparse JL\n",
    "2. Muliplicative Updates\n",
    "    - i) Randomized Projected NMF\n",
    "        * a) Gaussian Test Matrix\n",
    "        * b) SRHT Test Matrix\n",
    "        * c) SRFT Test Matrix\n",
    "        * d) Count Sketch Matrix\n",
    "        * e) Sparse JL\n",
    "    - ii) Structured Random Projected NMF\n",
    "        * a) Gaussian Test Matrix\n",
    "        * b) SRHT Test Matrix\n",
    "        * c) SRFT Test Matrix\n",
    "        * d) Count Sketch Matrix\n",
    "        * e) Sparse JL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"MU C\": nmf_compress_mu,\n",
    "    'MU SC': nmf_structured_compress_mu,\n",
    "    'HALS C': nmf_compress_hals,\n",
    "    'HALS SC': nmf_structured_compress_hals\n",
    "}\n",
    "\n",
    "projection_types = [\n",
    "    'gaussian',\n",
    "    'srht',\n",
    "    'srft',\n",
    "    'sparse-jl',\n",
    "    'count-sketch',\n",
    "]\n",
    "\n",
    "stats = {\n",
    "    'time': {method: defaultdict(list) for method in methods},\n",
    "    'errors': {method: defaultdict(list) for method in methods},\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "sizes = np.arange(1_00, 1_001, 1_00)\n",
    "runs = 10\n",
    "r = 20\n",
    "for n in sizes:\n",
    "    # Generate A (n x 0.75n)\n",
    "    np.random.seed(1)\n",
    "    A, _, _= generate_synthetic_matrix(n,r,delta = 1.0)\n",
    "    for method_name, method in methods.items():\n",
    "        for projection in projection_types:\n",
    "            total_times = [] \n",
    "            total_errors = []       \n",
    "            for i in range(runs):\n",
    "                # Set seed per run\n",
    "                seed = i + 1\n",
    "                \n",
    "                # Time NMF Method\n",
    "                start_time = timeit.default_timer()\n",
    "                _, _, errors = method(A, r, random_state=seed,projection_type = projection)\n",
    "                time = timeit.default_timer() - start_time\n",
    "\n",
    "                # Store\n",
    "                total_times.append(time)\n",
    "                total_errors.append(errors[-1])\n",
    "            \n",
    "            # Store average times\n",
    "            stats['time'][method_name][projection].append(np.mean(total_times))\n",
    "            stats['errors'][method_name][projection].append(np.mean(total_errors))\n",
    "    \n",
    "    print(f'Completed benchmarking for matrix size: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_errors_df = pd.DataFrame(stats['errors']['HALS SC'],index = sizes)\n",
    "mu_times_df = pd.DataFrame(stats['time']['HALS SC'],index = sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "# Add time traces (left plot) with assigned colors\n",
    "for method in mu_times_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mu_times_df.index,\n",
    "            y=mu_times_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=True,  # Explicit color assignment\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Add error traces (right plot) with same colors\n",
    "for method in mu_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=mu_errors_df.index,\n",
    "            y=mu_errors_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=False,# Same color as left plot\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Computation Time and Reconstruction Error by Method',\n",
    "    xaxis_title='Size (n)',\n",
    "    yaxis_title='Time (s)',\n",
    "    xaxis2_title='Size (n)',\n",
    "    yaxis2_title='Reconstruction Error',\n",
    "\n",
    ")\n",
    "\n",
    "\"\"\"    \n",
    "legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.1,\n",
    "    xanchor=\"center\",\n",
    "    x=0.5\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Matrix Projection Algorithms**\n",
    "\n",
    "First, we compare the compression time for each of the tested matrix transformation techinques. Specifically, we show the run times of only computing the initial matrix projection for both random projection and structured random projection using RPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Standard Randomized Projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = np.arange(100, 1_001, 100)\n",
    "runs = 10\n",
    "k = 100\n",
    "methods = {\n",
    "    \"Gaussian\": gaussian_random_matrix,\n",
    "    \"SRHT\": srht_matrix,\n",
    "    \"SRFT\": srft_matrix,\n",
    "    \"CountSketch\": countsketch_matrix,\n",
    "    \"Sparse JL\": lambda n, k, seed: sparse_jl_matrix(n, k, s=3, seed=seed)\n",
    "}\n",
    "times = {method: [] for method in methods}\n",
    "\n",
    "for n in sizes:\n",
    "    # Generate Random Matrix A to Project\n",
    "    np.random.seed(1)\n",
    "    A = np.random.randn(n, k)\n",
    "\n",
    "    for method_name, method in methods.items():\n",
    "        run_times = []\n",
    "        for i in range(runs):\n",
    "            seed = i + 1\n",
    "\n",
    "            # Get Projection Matrix\n",
    "            sigma = method(k, n, seed=seed)\n",
    "            \n",
    "            # Time Methods\n",
    "            timer = timeit.Timer(lambda: sigma @ A)\n",
    "            # Average over 10 runs\n",
    "            runtime = timer.timeit(number=10) / 10\n",
    "            \n",
    "            run_times.append(runtime)\n",
    "        times[method_name].append(np.mean(run_times))\n",
    "    print(f'Calculating for Matrix of Size: {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Standard Random Projections*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_df = pd.DataFrame(times,index = sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "for method in times_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = times_df.index,\n",
    "            y = times_df[method],\n",
    "            name = method\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'Time (s) vs Matrix Size by Compression Algorithm',\n",
    "    xaxis_title = 'n',\n",
    "    yaxis_title = 'Time (s)',\n",
    "    template = 'plotly_white'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Structured Random Projection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have all these matrix generation functions defined\n",
    "methods = {\n",
    "    \"Gaussian\": gaussian_random_matrix,\n",
    "    \"SRHT\": srht_matrix,\n",
    "    \"SRFT\": srft_matrix,\n",
    "    \"CountSketch\": countsketch_matrix,\n",
    "    \"Sparse JL\": lambda n, k, seed: sparse_jl_matrix(n, k, s=3, seed=seed)\n",
    "}\n",
    "\n",
    "# Initialize timing dictionaries\n",
    "times = {\n",
    "    'projection': {method: [] for method in methods},\n",
    "    'rpi': {method: [] for method in methods},\n",
    "    'total': {method: [] for method in methods}\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "sizes = np.arange(100, 1_001, 100)\n",
    "runs = 10\n",
    "k = 100\n",
    "q = 2  # Number of power iterations for RPI\n",
    "\n",
    "for n in sizes:\n",
    "    # Generate Random Matrix A to Project\n",
    "    np.random.seed(1)\n",
    "    A = np.abs(np.random.randn(n, k))  # Note: A is k√ón (transposed from typical notation)\n",
    "    \n",
    "    for method_name, method in methods.items():\n",
    "        projection_times = []\n",
    "        rpi_times = []\n",
    "        total_times = []\n",
    "        \n",
    "        for i in range(runs):\n",
    "            seed = i + 1\n",
    "\n",
    "            # Time projection matrix generation\n",
    "            timer_proj = timeit.Timer(lambda: method(k, n, seed=seed))\n",
    "            proj_time = timer_proj.timeit(number=1)  # Single run as creation is deterministic per seed\n",
    "            \n",
    "            # Generate projection matrix\n",
    "            sigma = method(k, n, seed=seed)\n",
    "            \n",
    "            # Time projection operation\n",
    "            timer_mult = timeit.Timer(lambda: sigma @ A)\n",
    "            mult_time = timer_mult.timeit(number=10) / 10\n",
    "            \n",
    "            # Time RPI operation\n",
    "            timer_rpi = timeit.Timer(lambda: randomized_power_iteration(A, sigma, q))\n",
    "            rpi_time = timer_rpi.timeit(number=10) / 10\n",
    "            \n",
    "            projection_times.append(proj_time + mult_time)\n",
    "            rpi_times.append(rpi_time)\n",
    "            total_times.append(proj_time + mult_time + rpi_time)\n",
    "        \n",
    "        # Store average times\n",
    "        times['projection'][method_name].append(np.mean(projection_times))\n",
    "        times['rpi'][method_name].append(np.mean(rpi_times))\n",
    "        times['total'][method_name].append(np.mean(total_times))\n",
    "    \n",
    "    print(f'Completed benchmarking for matrix size: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_times_df = pd.DataFrame(times['projection'],index = sizes)\n",
    "total_times_df = pd.DataFrame(times['total'],index = sizes)\n",
    "rpi_times_df = pd.DataFrame(times['rpi'],index = sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Structured Random Compression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for method in rpi_times_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x = rpi_times_df.index,\n",
    "            y = rpi_times_df[method],\n",
    "            name = method\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Time Breakdown by Component of Algorithm*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = rpi_times_df.columns  \n",
    "\n",
    "plots_per_row = 3\n",
    "num_methods = len(methods)\n",
    "num_rows = math.ceil(num_methods / plots_per_row)\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(\n",
    "    rows=num_rows, \n",
    "    cols=plots_per_row,\n",
    "    subplot_titles=[f\"{method}\" for method in methods],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "for idx, method in enumerate(methods):\n",
    "    row = idx // plots_per_row + 1\n",
    "    col = idx % plots_per_row + 1\n",
    "\n",
    "    # RPI Proportion\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=rpi_times_df.index,\n",
    "            y=rpi_times_df[method] / total_times_df[method],\n",
    "            name='RPI',\n",
    "            mode='lines',\n",
    "            stackgroup='one',\n",
    "            line=dict(width=0.5),\n",
    "            fillcolor='rgba(0, 100, 80, 0.3)',\n",
    "            legendgroup=method,\n",
    "            showlegend=(idx == 0)\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    # Projection Proportion\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=rpi_times_df.index,\n",
    "            y=proj_times_df[method] / total_times_df[method],\n",
    "            name='Generation + Multiplication',\n",
    "            mode='lines',\n",
    "            stackgroup='one',\n",
    "            line=dict(width=0.5),\n",
    "            fillcolor='rgba(100, 0, 80, 0.3)',\n",
    "            legendgroup=method,\n",
    "            showlegend= (idx == 0)\n",
    "        ),\n",
    "        row=row, col=col\n",
    "    )\n",
    "    \n",
    "    # Y-axis in percent\n",
    "    fig.update_yaxes(\n",
    "        tickformat=',.0%',\n",
    "        range=[0, 1],\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Time Breakdown by Method\",\n",
    "    height=300 * num_rows,\n",
    "    hovermode='x unified',\n",
    "    legend=dict(orientation='h', yanchor='bottom', y=-0.2, xanchor='center', x=0.5),\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **NMF Algorithms**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$\\delta = 1$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"MU\": nmf_mu,\n",
    "    \"MU C\": nmf_compress_mu,\n",
    "    \"MU SC\": nmf_structured_compress_mu,\n",
    "    \"HALS\": nmf_hals,\n",
    "    \"HALS C\":nmf_compress_hals,\n",
    "    \"HALS SC\":nmf_structured_compress_hals,\n",
    "}\n",
    "\n",
    "stats = {\n",
    "    'time': {method: [] for method in methods},\n",
    "    'errors': {method: [] for method in methods},\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "sizes = np.arange(1_000, 5_001, 1_000)\n",
    "runs = 10\n",
    "r = 20\n",
    "for n in sizes:\n",
    "    # Generate A (n x 0.75n)\n",
    "    np.random.seed(1)\n",
    "    A, _, _= generate_synthetic_matrix(n,r,delta = 1.0)\n",
    "    for method_name, method in methods.items():\n",
    "\n",
    "        total_times = [] \n",
    "        total_errors = []       \n",
    "        for i in range(runs):\n",
    "            # Set seed per run\n",
    "            seed = i + 1\n",
    "            \n",
    "            # Time NMF Method\n",
    "            start_time = timeit.default_timer()\n",
    "            _, _, errors = method(A, r, random_state=seed)\n",
    "            time = timeit.default_timer() - start_time\n",
    "\n",
    "            # Store\n",
    "            total_times.append(time)\n",
    "            total_errors.append(errors[-1])\n",
    "        \n",
    "        # Store average times\n",
    "        stats['time'][method_name].append(np.mean(total_times))\n",
    "        stats['errors'][method_name].append(np.mean(total_errors))\n",
    "    \n",
    "    print(f'Completed benchmarking for matrix size: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_times_df = pd.DataFrame(stats['time'],index = sizes)\n",
    "nmf_errors_df = pd.DataFrame(stats['errors'],index = sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Standard NMF Implementations*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create a color map for consistent colors\n",
    "color_map = {\n",
    "    'MU': '#1f77b4',  # Blue\n",
    "    'MU C': '#9467bd',\n",
    "    'MU SC': '#e377c2',\n",
    "    'HALS': '#ff7f0e',  # Orange\n",
    "    'HALS C': '#17becf',\n",
    "    'HALS SC': '#bcbd22'\n",
    "    # Add more methods as needed\n",
    "}\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "# Add time traces (left plot) with assigned colors\n",
    "for method in nmf_times_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=nmf_times_df.index,\n",
    "            y=nmf_times_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=True,\n",
    "            line=dict(color=color_map[method])  # Explicit color assignment\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Add error traces (right plot) with same colors\n",
    "for method in nmf_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=nmf_errors_df.index,\n",
    "            y=nmf_errors_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=False,\n",
    "            line=dict(color=color_map[method])  # Same color as left plot\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Computation Time and Reconstruction Error by Method',\n",
    "    xaxis_title='Size (n)',\n",
    "    yaxis_title='Time (s)',\n",
    "    xaxis2_title='Size (n)',\n",
    "    yaxis2_title='Reconstruction Error',\n",
    "\n",
    ")\n",
    "\n",
    "\"\"\"    \n",
    "legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.1,\n",
    "    xanchor=\"center\",\n",
    "    x=0.5\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*$\\delta = 0.01$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"MU\": nmf_mu,\n",
    "    \"HALS\": nmf_hals,\n",
    "}\n",
    "\n",
    "stats = {\n",
    "    'time': {method: [] for method in methods},\n",
    "    'errors': {method: [] for method in methods},\n",
    "}\n",
    "\n",
    "# Parameters\n",
    "sizes = np.arange(1_00, 1_001, 1_00)\n",
    "runs = 10\n",
    "r = 20\n",
    "for n in sizes:\n",
    "    # Generate A (n x 0.75n)\n",
    "    np.random.seed(1)\n",
    "    A, _, _= generate_synthetic_matrix(n,r,delta = 0.01)\n",
    "    for method_name, method in methods.items():\n",
    "\n",
    "        total_times = [] \n",
    "        total_errors = []       \n",
    "        for i in range(runs):\n",
    "            # Set seed per run\n",
    "            seed = i + 1\n",
    "            \n",
    "            # Time NMF Method\n",
    "            start_time = timeit.default_timer()\n",
    "            _, _, errors = method(A, r, random_state=seed)\n",
    "            time = timeit.default_timer() - start_time\n",
    "\n",
    "            # Store\n",
    "            total_times.append(time)\n",
    "            total_errors.append(errors[-1])\n",
    "        \n",
    "        # Store average times\n",
    "        stats['time'][method_name].append(np.mean(total_times))\n",
    "        stats['errors'][method_name].append(np.mean(total_errors))\n",
    "    \n",
    "    print(f'Completed benchmarking for matrix size: {n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_times_df = pd.DataFrame(stats['time'],index = sizes)\n",
    "nmf_errors_df = pd.DataFrame(stats['errors'],index = sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a color map for consistent colors\n",
    "color_map = {\n",
    "    'MU': '#1f77b4',  # Blue\n",
    "    'HALS': '#ff7f0e',  # Orange\n",
    "    # Add more methods as needed\n",
    "}\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "\n",
    "# Add time traces (left plot) with assigned colors\n",
    "for method in nmf_times_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=nmf_times_df.index,\n",
    "            y=nmf_times_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=True,\n",
    "            line=dict(color=color_map[method])  # Explicit color assignment\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "# Add error traces (right plot) with same colors\n",
    "for method in nmf_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=nmf_errors_df.index,\n",
    "            y=nmf_errors_df[method],\n",
    "            name=method,\n",
    "            legendgroup=method,\n",
    "            showlegend=False,\n",
    "            line=dict(color=color_map[method])  # Same color as left plot\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Computation Time and Reconstruction Error by Method',\n",
    "    xaxis_title='Size (n)',\n",
    "    yaxis_title='Time (s)',\n",
    "    xaxis2_title='Size (n)',\n",
    "    yaxis2_title='Reconstruction Error',\n",
    "\n",
    ")\n",
    "\n",
    "\"\"\"    \n",
    "legend=dict(\n",
    "    orientation=\"h\",\n",
    "    yanchor=\"bottom\",\n",
    "    y=1.1,\n",
    "    xanchor=\"center\",\n",
    "    x=0.5\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ***Application 1: CBCL***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "X_faces = fetch_olivetti_faces(shuffle=True).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Method Benchmarks*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_faces.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = {\n",
    "    \"MU C\": nmf_compress_mu,\n",
    "    'MU SC': nmf_structured_compress_mu,\n",
    "    'HALS C': nmf_compress_hals,\n",
    "    'HALS SC': nmf_structured_compress_hals\n",
    "}\n",
    "\n",
    "projection_types = [\n",
    "    'gaussian',\n",
    "    # 'srht',\n",
    "    # 'givens',\n",
    "    'srft',\n",
    "    'sparse-jl',\n",
    "    'count-sketch',\n",
    "]\n",
    "\n",
    "stats = benchmark_faces(X_faces,methods,projection_types,r=49,runs=10)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HALS SC performs the best, across all projection methods, but takes the longest to compute. \n",
    "\n",
    "HALS C performs the besst with traditional gaussian compression, MU C performs the best with count-sketch, and MU SC with gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutiplicative Updates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard MU Algorithm\n",
    "X_mu,Y_mu,errors_mu = nmf_mu(X_faces,49,max_iter=100)\n",
    "\n",
    "# Standard Compressed MU\n",
    "X_c_mu,Y_c_mu,errors_s_mu = nmf_compress_mu(X_faces,49,max_iter=100,projection_type='count-sketch')\n",
    "\n",
    "# Structured Compressed MU\n",
    "X_sc_mu,Y_sc_mu,errors_sc_mu = nmf_structured_compress_mu(X_faces,49,max_iter=100,projection_type='gaussian')\n",
    "\n",
    "# Errors \n",
    "mu_errors_df = pd.DataFrame({'MU':errors_mu,\n",
    "              'C MU':errors_s_mu,\n",
    "              'SC MU':errors_sc_mu})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Reconstruction Errors*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for method in mu_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y = mu_errors_df[method],\n",
    "            name = method\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'CBCL Reconstruction Error by HALS Method',\n",
    "    yaxis_title = 'Reconstruction Error',\n",
    "    xaxis_title = 'Iteration'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Visual Reconstruction Error by Method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 4\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4, cols=4,\n",
    "    subplot_titles=([\"Original Images\"] + [' ']*3 + \n",
    "                   [\"MU\"] + [' ']*3 + \n",
    "                   [\"Comp. MU (Count-Sketch)\"] + [' ']*3 + \n",
    "                   [\"Struct. Comp. MU (Gaussian)\"] + [' ']*3),\n",
    "    vertical_spacing=0.05,\n",
    "    horizontal_spacing=0.02\n",
    ")\n",
    "\n",
    "matrix_pairs = [\n",
    "    (\"Original\", X_faces),\n",
    "    (\"MU\", X_mu @ Y_mu),\n",
    "    (\"Compressed MU\", X_c_mu @ Y_c_mu),\n",
    "    (\"Structured Compressed MU\", X_sc_mu @ Y_sc_mu)\n",
    "]\n",
    "\n",
    "for row, (name, Z) in enumerate(matrix_pairs, start=1):\n",
    "    for col in range(1, n_images + 1):\n",
    "        z = Z[col-1].reshape(64, 64)\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=z, colorscale='gray', showscale=False),\n",
    "            row=row, col=col\n",
    "        )\n",
    "  \n",
    "fig.update_layout(\n",
    "    title=\"NMF MU Reconstruction\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    font=dict(size=8), \n",
    "    margin=dict(l=10, r=10, b=10, t=40, pad=0), \n",
    "    plot_bgcolor='white', \n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.update_annotations(font_size=10)\n",
    "fig.update_yaxes(autorange='reversed')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hierarchical Least Squares**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard MU Algorithm\n",
    "X_hals,Y_hals,errors_hals = nmf_hals(X_faces,49,max_iter=100)\n",
    "\n",
    "# Standard Compressed MU\n",
    "X_c_hals,Y_c_hals,errors_s_hals = nmf_compress_hals(X_faces,49,max_iter=100,projection_type='gaussian')\n",
    "\n",
    "# Structured Compressed MU\n",
    "X_sc_hals,Y_sc_hals,errors_sc_hals = nmf_structured_compress_hals(X_faces,49,max_iter=100,projection_type='count-sketch')\n",
    "\n",
    "# Errors dataframe\n",
    "hals_errors_df = pd.DataFrame({'HALS':errors_hals,\n",
    "              'C HALS':errors_s_hals,\n",
    "              'SC HALS':errors_sc_hals})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Reconstruction Error*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for method in hals_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y = hals_errors_df[method],\n",
    "            name = method\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'CBCL Reconstruction Error by HALS Method',\n",
    "    yaxis_title = 'Reconstruction Error',\n",
    "    xaxis_title = 'Iteration'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Plot: Visual Reconstruction Error by Method*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = 4\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=4, cols=4,\n",
    "    subplot_titles=([\"Original Images\"] + [' ']*3 + \n",
    "                   [\"HALS\"] + [' ']*3 + \n",
    "                   [\"Comp. HALS (Gaussian)\"] + [' ']*3 + \n",
    "                   [\"Struct. Comp. HALS (Count-Sketch)\"] + [' ']*3),\n",
    "    vertical_spacing=0.05,\n",
    "    horizontal_spacing=0.02\n",
    ")\n",
    "\n",
    "matrix_pairs = [\n",
    "    (\"Original\", X_faces),\n",
    "    (\"HALS\", X_hals @ Y_hals),\n",
    "    (\"Compressed HALS\", X_c_hals @ Y_c_hals),\n",
    "    (\"Structured Compressed HALS\", X_sc_hals @ Y_sc_hals)\n",
    "]\n",
    "\n",
    "for row, (name, Z) in enumerate(matrix_pairs, start=1):\n",
    "    for col in range(1, n_images + 1):\n",
    "        z = Z[col-1].reshape(64, 64)\n",
    "        fig.add_trace(\n",
    "            go.Heatmap(z=z, colorscale='gray', showscale=False),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"NMF HALS Reconstruction\",\n",
    "    width=800,\n",
    "    height=600,\n",
    "    font=dict(size=8),  \n",
    "    margin=dict(l=10, r=10, b=10, t=40, pad=0), \n",
    "    plot_bgcolor='white',\n",
    "    paper_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.update_annotations(font_size=10)\n",
    "fig.update_yaxes(autorange='reversed')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Harvard Microarray Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('dataseta_12600gene.xls')\n",
    "X = df.iloc[:, 2:].values \n",
    "\n",
    "# 2. Preprocessing\n",
    "X = np.where(X < 0, 0, X)\n",
    "X = np.log2(X + 1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Multiplicative Updates*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard MU Algorithm\n",
    "X_mu,Y_mu,errors_mu = nmf_mu(X,5,max_iter=100)\n",
    "\n",
    "# Standard Compressed MU\n",
    "X_c_mu,Y_c_mu,errors_s_mu = nmf_compress_mu(X,5,max_iter=100)\n",
    "\n",
    "# Structured Compressed MU\n",
    "X_sc_mu,Y_sc_mu,errors_sc_mu = nmf_structured_compress_mu(X,5,max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_errors_df = pd.DataFrame({'MU':errors_mu,\n",
    "              'C MU':errors_s_mu,\n",
    "              'SC MU':errors_sc_mu})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "for method in mu_errors_df.columns:\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            y = mu_errors_df[method],\n",
    "            name = method\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title = 'Microarray Reconstruction Error by MU Method',\n",
    "    yaxis_title = 'Reconstruction Error',\n",
    "    xaxis_title = 'Iteration',\n",
    "    width = 600,\n",
    "    height = 500\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
