{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c971689",
   "metadata": {},
   "source": [
    "**Section 5b: Empirical Performance - 20 NewsGroups**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd5676",
   "metadata": {},
   "source": [
    "*Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import defaultdict\n",
    "from random_matrix import *\n",
    "from nmf import *\n",
    "from benchmark import *\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d4974",
   "metadata": {},
   "source": [
    "*Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877aef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")\n",
    "\n",
    "texts = newsgroups.data \n",
    "true_labels = newsgroups.target\n",
    "\n",
    "# Create TF-IDF vectorizer \n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,        \n",
    "    stop_words='english',    \n",
    "    min_df=5,                \n",
    "    max_df=0.7               \n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(texts)\n",
    "\n",
    "# Convert to NCW\n",
    "e = np.ones(X_tfidf.shape[1]) \n",
    "term_weights = X_tfidf.T @ X_tfidf @ e  \n",
    "term_weights = np.array(term_weights).flatten()  \n",
    "\n",
    "epsilon = 1e-6\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(term_weights + epsilon)) \n",
    "\n",
    "X_ncw = X_tfidf @ D_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f548215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7532, 5000)\n",
      "Sparsity: 0.9914051248008497\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {X_ncw.shape}')\n",
    "print(f'Sparsity: {1 - len(np.nonzero(X_ncw)[0])/(X_ncw.shape[0]*X_ncw.shape[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74978796",
   "metadata": {},
   "source": [
    "*Benchmark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb24c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes clustering accuracy (AC) using the Kuhn-Munkres algorithm\n",
    "    to find the optimal mapping from predicted clusters to true labels.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)  # maximize accuracy\n",
    "    return cm[row_ind, col_ind].sum() / np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d63f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed MU C, gaussian, k=20\n",
      "Completed MU C, srht, k=20\n",
      "Completed MU C, srft, k=20\n",
      "Completed MU C, sparse-jl, k=20\n",
      "Completed MU C, count-sketch, k=20\n",
      "Completed MU SC, gaussian, k=20\n",
      "Completed MU SC, srht, k=20\n",
      "Completed MU SC, srft, k=20\n",
      "Completed MU SC, sparse-jl, k=20\n",
      "Completed MU SC, count-sketch, k=20\n",
      "Completed HALS C, gaussian, k=20\n",
      "Completed HALS C, srht, k=20\n",
      "Completed HALS C, srft, k=20\n",
      "Completed HALS C, sparse-jl, k=20\n",
      "Completed HALS C, count-sketch, k=20\n",
      "Completed HALS SC, gaussian, k=20\n",
      "Completed HALS SC, srht, k=20\n",
      "Completed HALS SC, srft, k=20\n",
      "Completed HALS SC, sparse-jl, k=20\n",
      "Completed HALS SC, count-sketch, k=20\n",
      "Completed baseline MU, k=20\n",
      "Completed baseline HALS, k=20\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "def run_experiment(X_ncw, true_labels,k_values,runs,methods,methods_baseline,projection_types):\n",
    "    results = []\n",
    "    \n",
    "    # First run baseline methods (no projections)\n",
    "    for method_name, method in methods_baseline.items():\n",
    "        for k in k_values:\n",
    "            metrics = {\n",
    "                'errors': [],\n",
    "                'times': [],\n",
    "                'ARI': [],\n",
    "                'AC': [],\n",
    "                'NMI': []\n",
    "            }\n",
    "            \n",
    "            for seed in range(1, runs + 1):\n",
    "                # Time NMF Method\n",
    "                start_time = timeit.default_timer()\n",
    "                W, H, errors = method(X_ncw, k, random_state=seed)\n",
    "                elapsed_time = timeit.default_timer() - start_time\n",
    "\n",
    "                # Calculate metrics\n",
    "                pred_labels = W.argmax(axis=1)\n",
    "                \n",
    "                metrics['errors'].append(errors[-1])\n",
    "                metrics['times'].append(elapsed_time)\n",
    "                metrics['ARI'].append(adjusted_rand_score(true_labels, pred_labels))\n",
    "                metrics['AC'].append(clustering_accuracy(true_labels, pred_labels))\n",
    "                metrics['NMI'].append(normalized_mutual_info_score(true_labels, pred_labels))\n",
    "            \n",
    "            # Store results for baseline\n",
    "            results.append({\n",
    "                'Method': method_name,\n",
    "                'Projection': 'none',  # Mark as baseline\n",
    "                'K': k,\n",
    "                'Time': np.mean(metrics['times']),\n",
    "                'Errors': np.mean(metrics['errors']),\n",
    "                'ARI': np.mean(metrics['ARI']),\n",
    "                'AC': np.mean(metrics['AC']),\n",
    "                'NMI': np.mean(metrics['NMI'])\n",
    "            })\n",
    "            \n",
    "            print(f\"Completed baseline {method_name}, k={k}\")\n",
    "    \n",
    "    # Then run projection methods\n",
    "    for method_name, method in methods.items():\n",
    "        for projection in projection_types:\n",
    "            for k in k_values:\n",
    "                metrics = {\n",
    "                    'errors': [],\n",
    "                    'times': [],\n",
    "                    'ARI': [],\n",
    "                    'AC': [],\n",
    "                    'NMI': []\n",
    "                }\n",
    "                \n",
    "                for seed in range(1, runs + 1):\n",
    "                    # Time NMF Method\n",
    "                    start_time = timeit.default_timer()\n",
    "                    W, H, errors = method(X_ncw, k, random_state=seed, projection_type=projection)\n",
    "                    elapsed_time = timeit.default_timer() - start_time\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    pred_labels = W.argmax(axis=1)\n",
    "                    \n",
    "                    metrics['errors'].append(errors[-1])\n",
    "                    metrics['times'].append(elapsed_time)\n",
    "                    metrics['ARI'].append(adjusted_rand_score(true_labels, pred_labels))\n",
    "                    metrics['AC'].append(clustering_accuracy(true_labels, pred_labels))\n",
    "                    metrics['NMI'].append(normalized_mutual_info_score(true_labels, pred_labels))\n",
    "                \n",
    "                # Store results for this configuration\n",
    "                results.append({\n",
    "                    'Method': method_name,\n",
    "                    'Projection': projection,\n",
    "                    'K': k,\n",
    "                    'Time': np.mean(metrics['times']),\n",
    "                    'Errors': np.mean(metrics['errors']),\n",
    "                    'ARI': np.mean(metrics['ARI']),\n",
    "                    'AC': np.mean(metrics['AC']),\n",
    "                    'NMI': np.mean(metrics['NMI'])\n",
    "                })\n",
    "                \n",
    "                print(f\"Completed {method_name}, {projection}, k={k}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "methods = {\n",
    "    \"MU C\": nmf_compress_mu,\n",
    "    'MU SC': nmf_structured_compress_mu,\n",
    "    'HALS C': nmf_compress_hals,\n",
    "    'HALS SC': nmf_structured_compress_hals\n",
    "}\n",
    "\n",
    "methods_baseline = {\n",
    "    \"MU\": nmf_mu,\n",
    "    'HALS': nmf_hals,\n",
    "}\n",
    "\n",
    "projection_types = [\n",
    "    'gaussian',\n",
    "    'srht',\n",
    "    'srft',\n",
    "    'sparse-jl',\n",
    "    'count-sketch',\n",
    "]\n",
    "\n",
    "runs = 10\n",
    "k_values = range(20, 21, 2)\n",
    "\n",
    "# Run the experiment\n",
    "rows_compressed = run_experiment(X_ncw, true_labels,k_values,runs,methods,{},projection_types)\n",
    "rows_baseline = run_experiment(X_ncw, true_labels,k_values,runs,{},methods_baseline,projection_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a4c03",
   "metadata": {},
   "source": [
    "*Baseline Stats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bd0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = pd.DataFrame(rows_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216e3f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>NMI</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS</th>\n",
       "      <td>0.0805</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>14.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU</th>\n",
       "      <td>0.3608</td>\n",
       "      <td>0.4104</td>\n",
       "      <td>20.9999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AC     NMI     Time\n",
       "Method                         \n",
       "HALS    0.0805  0.0634  14.2363\n",
       "MU      0.3608  0.4104  20.9999"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline.pivot_table(values = ['AC','NMI','Time'],index = ['Method']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8123d",
   "metadata": {},
   "source": [
    "*Compressed Stats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6c57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(rows_compressed)[['Method','Projection','Time','AC','NMI']].pivot_table(values = ['AC','NMI'],columns = ['Projection'],index=['Method'])\n",
    "df_time = pd.DataFrame(rows_compressed)[['Method','Projection','Time','AC','NMI']].pivot_table(values = ['Time'],columns = ['Projection'],index=['Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101934cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">AC</th>\n",
       "      <th colspan=\"5\" halign=\"left\">NMI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projection</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS C</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HALS SC</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU C</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU SC</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AC                                         NMI           \\\n",
       "Projection count-sketch gaussian sparse-jl  srft  srht count-sketch gaussian   \n",
       "Method                                                                         \n",
       "HALS C             0.06     0.06      0.07  0.06  0.06         0.00     0.00   \n",
       "HALS SC            0.08     0.08      0.08  0.08  0.08         0.08     0.07   \n",
       "MU C               0.07     0.08      0.07  0.08  0.07         0.01     0.02   \n",
       "MU SC              0.39     0.35      0.40  0.34  0.38         0.36     0.35   \n",
       "\n",
       "                                  \n",
       "Projection sparse-jl  srft  srht  \n",
       "Method                            \n",
       "HALS C          0.01  0.01  0.00  \n",
       "HALS SC         0.07  0.07  0.07  \n",
       "MU C            0.01  0.01  0.01  \n",
       "MU SC           0.37  0.35  0.38  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cf6fa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projection</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS C</th>\n",
       "      <td>11.63</td>\n",
       "      <td>11.66</td>\n",
       "      <td>11.64</td>\n",
       "      <td>11.55</td>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HALS SC</th>\n",
       "      <td>11.81</td>\n",
       "      <td>11.76</td>\n",
       "      <td>11.78</td>\n",
       "      <td>11.73</td>\n",
       "      <td>12.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU C</th>\n",
       "      <td>12.06</td>\n",
       "      <td>11.86</td>\n",
       "      <td>12.06</td>\n",
       "      <td>11.97</td>\n",
       "      <td>11.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU SC</th>\n",
       "      <td>12.21</td>\n",
       "      <td>12.21</td>\n",
       "      <td>12.22</td>\n",
       "      <td>12.14</td>\n",
       "      <td>13.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time                                 \n",
       "Projection count-sketch gaussian sparse-jl   srft   srht\n",
       "Method                                                  \n",
       "HALS C            11.63    11.66     11.64  11.55  11.64\n",
       "HALS SC           11.81    11.76     11.78  11.73  12.42\n",
       "MU C              12.06    11.86     12.06  11.97  11.88\n",
       "MU SC             12.21    12.21     12.22  12.14  13.04"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcb12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
