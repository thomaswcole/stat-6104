{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c971689",
   "metadata": {},
   "source": [
    "**Section 5b: Empirical Performance - 20 NewsGroups**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd5676",
   "metadata": {},
   "source": [
    "*Imports*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccd26ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from collections import defaultdict\n",
    "from random_matrix import *\n",
    "from nmf import *\n",
    "from benchmark import *\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d4974",
   "metadata": {},
   "source": [
    "*Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "877aef80",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='test',\n",
    "    remove=('headers', 'footers', 'quotes')\n",
    ")\n",
    "\n",
    "texts = newsgroups.data \n",
    "true_labels = newsgroups.target\n",
    "\n",
    "# Create TF-IDF vectorizer \n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,        \n",
    "    stop_words='english',    \n",
    "    min_df=5,                \n",
    "    max_df=0.7               \n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(texts)\n",
    "\n",
    "# Convert to NCW\n",
    "e = np.ones(X_tfidf.shape[1]) \n",
    "term_weights = X_tfidf.T @ X_tfidf @ e  \n",
    "term_weights = np.array(term_weights).flatten()  \n",
    "\n",
    "epsilon = 1e-6\n",
    "D_inv_sqrt = np.diag(1 / np.sqrt(term_weights + epsilon)) \n",
    "\n",
    "X_ncw = X_tfidf @ D_inv_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f548215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (7532, 5000)\n",
      "Sparsity: 0.9914033988316516\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape: {X_ncw.shape}')\n",
    "print(f'Sparsity: {1 - len(np.nonzero(X_ncw)[0])/(X_ncw.shape[0]*X_ncw.shape[1])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74978796",
   "metadata": {},
   "source": [
    "*Benchmark*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb24c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes clustering accuracy (AC) using the Kuhn-Munkres algorithm\n",
    "    to find the optimal mapping from predicted clusters to true labels.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    row_ind, col_ind = linear_sum_assignment(-cm)  # maximize accuracy\n",
    "    return cm[row_ind, col_ind].sum() / np.sum(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13d63f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed MU C, gaussian, k=20\n",
      "Completed MU C, srht, k=20\n",
      "Completed MU C, srft, k=20\n",
      "Completed MU C, sparse-jl, k=20\n",
      "Completed MU C, count-sketch, k=20\n",
      "Completed MU SC, gaussian, k=20\n",
      "Completed MU SC, srht, k=20\n",
      "Completed MU SC, srft, k=20\n",
      "Completed MU SC, sparse-jl, k=20\n",
      "Completed MU SC, count-sketch, k=20\n",
      "Completed HALS C, gaussian, k=20\n",
      "Completed HALS C, srht, k=20\n",
      "Completed HALS C, srft, k=20\n",
      "Completed HALS C, sparse-jl, k=20\n",
      "Completed HALS C, count-sketch, k=20\n",
      "Completed HALS SC, gaussian, k=20\n",
      "Completed HALS SC, srht, k=20\n",
      "Completed HALS SC, srft, k=20\n",
      "Completed HALS SC, sparse-jl, k=20\n",
      "Completed HALS SC, count-sketch, k=20\n",
      "Completed baseline MU, k=20\n",
      "Completed baseline HALS, k=20\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "def run_experiment(X_ncw, true_labels,k_values,runs,methods,methods_baseline,projection_types):\n",
    "    results = []\n",
    "    \n",
    "    # First run baseline methods (no projections)\n",
    "    for method_name, method in methods_baseline.items():\n",
    "        for k in k_values:\n",
    "            metrics = {\n",
    "                'errors': [],\n",
    "                'times': [],\n",
    "                'ARI': [],\n",
    "                'AC': [],\n",
    "                'NMI': []\n",
    "            }\n",
    "            \n",
    "            for seed in range(1, runs + 1):\n",
    "                # Time NMF Method\n",
    "                start_time = timeit.default_timer()\n",
    "                W, H, errors = method(X_ncw, k, random_state=seed)\n",
    "                elapsed_time = timeit.default_timer() - start_time\n",
    "\n",
    "                # Calculate metrics\n",
    "                pred_labels = W.argmax(axis=1)\n",
    "                \n",
    "                metrics['errors'].append(errors[-1])\n",
    "                metrics['times'].append(elapsed_time)\n",
    "                metrics['ARI'].append(adjusted_rand_score(true_labels, pred_labels))\n",
    "                metrics['AC'].append(clustering_accuracy(true_labels, pred_labels))\n",
    "                metrics['NMI'].append(normalized_mutual_info_score(true_labels, pred_labels))\n",
    "            \n",
    "            # Store results for baseline\n",
    "            results.append({\n",
    "                'Method': method_name,\n",
    "                'Projection': 'none',  # Mark as baseline\n",
    "                'K': k,\n",
    "                'Time': np.mean(metrics['times']),\n",
    "                'Errors': np.mean(metrics['errors']),\n",
    "                'ARI': np.mean(metrics['ARI']),\n",
    "                'AC': np.mean(metrics['AC']),\n",
    "                'NMI': np.mean(metrics['NMI'])\n",
    "            })\n",
    "            \n",
    "            print(f\"Completed baseline {method_name}, k={k}\")\n",
    "    \n",
    "    # Then run projection methods\n",
    "    for method_name, method in methods.items():\n",
    "        for projection in projection_types:\n",
    "            for k in k_values:\n",
    "                metrics = {\n",
    "                    'errors': [],\n",
    "                    'times': [],\n",
    "                    'ARI': [],\n",
    "                    'AC': [],\n",
    "                    'NMI': []\n",
    "                }\n",
    "                \n",
    "                for seed in range(1, runs + 1):\n",
    "                    # Time NMF Method\n",
    "                    start_time = timeit.default_timer()\n",
    "                    W, H, errors = method(X_ncw, k, random_state=seed, projection_type=projection)\n",
    "                    elapsed_time = timeit.default_timer() - start_time\n",
    "\n",
    "                    # Calculate metrics\n",
    "                    pred_labels = W.argmax(axis=1)\n",
    "                    \n",
    "                    metrics['errors'].append(errors[-1])\n",
    "                    metrics['times'].append(elapsed_time)\n",
    "                    metrics['ARI'].append(adjusted_rand_score(true_labels, pred_labels))\n",
    "                    metrics['AC'].append(clustering_accuracy(true_labels, pred_labels))\n",
    "                    metrics['NMI'].append(normalized_mutual_info_score(true_labels, pred_labels))\n",
    "                \n",
    "                # Store results for this configuration\n",
    "                results.append({\n",
    "                    'Method': method_name,\n",
    "                    'Projection': projection,\n",
    "                    'K': k,\n",
    "                    'Time': np.mean(metrics['times']),\n",
    "                    'Errors': np.mean(metrics['errors']),\n",
    "                    'ARI': np.mean(metrics['ARI']),\n",
    "                    'AC': np.mean(metrics['AC']),\n",
    "                    'NMI': np.mean(metrics['NMI'])\n",
    "                })\n",
    "                \n",
    "                print(f\"Completed {method_name}, {projection}, k={k}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "methods = {\n",
    "    \"MU C\": nmf_compress_mu,\n",
    "    'MU SC': nmf_structured_compress_mu,\n",
    "    'HALS C': nmf_compress_hals,\n",
    "    'HALS SC': nmf_structured_compress_hals\n",
    "}\n",
    "\n",
    "methods_baseline = {\n",
    "    \"MU\": nmf_mu,\n",
    "    'HALS': nmf_hals,\n",
    "}\n",
    "\n",
    "projection_types = [\n",
    "    'gaussian',\n",
    "    'srht',\n",
    "    'srft',\n",
    "    'sparse-jl',\n",
    "    'count-sketch',\n",
    "]\n",
    "\n",
    "runs = 10\n",
    "k_values = range(20, 21, 2)\n",
    "\n",
    "# Run the experiment\n",
    "rows_compressed = run_experiment(X_ncw, true_labels,k_values,runs,methods,{},projection_types)\n",
    "rows_baseline = run_experiment(X_ncw, true_labels,k_values,runs,{},methods_baseline,projection_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a4c03",
   "metadata": {},
   "source": [
    "*Baseline Stats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9bd0f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline = pd.DataFrame(rows_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "216e3f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AC</th>\n",
       "      <th>NMI</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS</th>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0751</td>\n",
       "      <td>10.5167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU</th>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>14.3510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AC     NMI     Time\n",
       "Method                         \n",
       "HALS    0.0841  0.0751  10.5167\n",
       "MU      0.3639  0.4089  14.3510"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline.pivot_table(values = ['AC','NMI','Time'],index = ['Method']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c8123d",
   "metadata": {},
   "source": [
    "*Compressed Stats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a6c57ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = pd.DataFrame(rows_compressed)[['Method','Projection','Time','AC','NMI']].pivot_table(values = ['AC','NMI'],columns = ['Projection'],index=['Method'])\n",
    "df_time = pd.DataFrame(rows_compressed)[['Method','Projection','Time','AC','NMI']].pivot_table(values = ['Time'],columns = ['Projection'],index=['Method'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "101934cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">AC</th>\n",
       "      <th colspan=\"5\" halign=\"left\">NMI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projection</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS C</th>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.0664</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HALS SC</th>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0827</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.0802</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>0.0703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU C</th>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU SC</th>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.3812</td>\n",
       "      <td>0.4001</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.3485</td>\n",
       "      <td>0.3688</td>\n",
       "      <td>0.3777</td>\n",
       "      <td>0.3738</td>\n",
       "      <td>0.3765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     AC                                             NMI  \\\n",
       "Projection count-sketch gaussian sparse-jl    srft    srht count-sketch   \n",
       "Method                                                                    \n",
       "HALS C           0.0668   0.0664    0.0632  0.0615  0.0614       0.0048   \n",
       "HALS SC          0.0816   0.0817    0.0806  0.0827  0.0812       0.0802   \n",
       "MU C             0.0766   0.0708    0.0737  0.0729  0.0743       0.0146   \n",
       "MU SC            0.3534   0.3812    0.4001  0.3739  0.3771       0.3485   \n",
       "\n",
       "                                               \n",
       "Projection gaussian sparse-jl    srft    srht  \n",
       "Method                                         \n",
       "HALS C       0.0042    0.0036  0.0030  0.0031  \n",
       "HALS SC      0.0755    0.0806  0.0717  0.0703  \n",
       "MU C         0.0114    0.0127  0.0100  0.0116  \n",
       "MU SC        0.3688    0.3777  0.3738  0.3765  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stats.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cf6fa4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Projection</th>\n",
       "      <th>count-sketch</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>sparse-jl</th>\n",
       "      <th>srft</th>\n",
       "      <th>srht</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HALS C</th>\n",
       "      <td>8.7212</td>\n",
       "      <td>8.5627</td>\n",
       "      <td>8.2775</td>\n",
       "      <td>8.0707</td>\n",
       "      <td>7.5491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HALS SC</th>\n",
       "      <td>8.4334</td>\n",
       "      <td>8.5587</td>\n",
       "      <td>8.3121</td>\n",
       "      <td>8.3823</td>\n",
       "      <td>8.6492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU C</th>\n",
       "      <td>8.7794</td>\n",
       "      <td>8.3193</td>\n",
       "      <td>8.5105</td>\n",
       "      <td>8.3630</td>\n",
       "      <td>8.0753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MU SC</th>\n",
       "      <td>8.7321</td>\n",
       "      <td>8.8139</td>\n",
       "      <td>8.7562</td>\n",
       "      <td>8.7441</td>\n",
       "      <td>9.0416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time                                   \n",
       "Projection count-sketch gaussian sparse-jl    srft    srht\n",
       "Method                                                    \n",
       "HALS C           8.7212   8.5627    8.2775  8.0707  7.5491\n",
       "HALS SC          8.4334   8.5587    8.3121  8.3823  8.6492\n",
       "MU C             8.7794   8.3193    8.5105  8.3630  8.0753\n",
       "MU SC            8.7321   8.8139    8.7562  8.7441  9.0416"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bcb12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
